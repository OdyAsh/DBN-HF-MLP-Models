{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hanin Monir Ismail 192895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to try multiple variations of the MLP network and evaluate their performance in classifying the wonders of the world images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Reproducable Code\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)\n",
    "\n",
    "# other standard imports. \"pip install -r requirements.txt\" to install dependencies and \"pip freeze > requirements.txt\" to update them\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "import PIL\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Functions\n",
    "def pklSave(contentToBeSaved, fullPath):\n",
    "    with open(fullPath, 'wb') as f:\n",
    "        pickle.dump(contentToBeSaved, f)\n",
    "\n",
    "def pklLoad(fullPath, convertToNumpyArray=False):\n",
    "    with open(fullPath, 'rb') as f:\n",
    "        content = pickle.load(f)\n",
    "    if convertToNumpyArray:\n",
    "        content = np.array(content)\n",
    "    return content\n",
    "\n",
    "def train_val_test_split(x, y, tr, va, te, **kwargs):\n",
    "    x_train, x_test_val, y_train, y_test_val = train_test_split(x, y, test_size=1-tr)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test_val, y_test_val, test_size=te/(te+va), **kwargs)\n",
    "    return (x_train, x_val, x_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different models on the images of size 128x128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the dataset to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pklLoad('../x128.pkl', convertToNumpyArray=True)\n",
    "y = pklLoad('../y.pkl', convertToNumpyArray=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters:\n",
    "<ul>\n",
    "    <li> Input layers: 1 </li>\n",
    "    <li> Hidden layer: 2, 50 neurons each </li>\n",
    "    <li> Activation function in the hidden layer: \"relu\" </li>\n",
    "    <li> output activation function: \"sigmoid\" </li>\n",
    "    <li> opitimizer: \"Adam\" </li>\n",
    "    <li>batch size= 32</li>\n",
    "    <li>epochs= 100 </li>\n",
    "<ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1 = tf.keras.models.Sequential(layers = None, name= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding layers to the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Input and 1st hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1.add(tf.keras.layers.Dense(units= 50, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1.add(tf.keras.layers.Dense(units= 50, activation= 'relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1.add(tf.keras.layers.Dense(units= 1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation of the model using \"Adam\" optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - 1s 4ms/step - loss: 2.1859 - accuracy: 0.1602\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 3.6337 - accuracy: 0.2026\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 2.8840 - accuracy: 0.2026\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 2.7462 - accuracy: 0.2026\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 2.6130 - accuracy: 0.2026\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 2.4201 - accuracy: 0.2026\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.2026\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.2026\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.2026\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.2026\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.2026\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.2026\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.2026\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.2026\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.2026\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.2026\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.2026\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.2026\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.2026\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.2026\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.2026\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.2026\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.2026\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.2026\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.2026\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.2026\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.2026\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.2026\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.2026\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.2026\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.2026\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.2026\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.2026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255a4a38d30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP1.fit(x_train, y_train, batch_size= 32, epochs= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model results accuracy is very low, it has scored an accuracy of 0.2026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1= MLP1.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy against epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = MLP1.fit(x_train, y_train,validation_split = 0.1, epochs=100, batch_size=4)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('First MLP accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss against epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('First MLP loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try adding a hidden layer to enhance the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters:\n",
    "<ul>\n",
    "    <li> Input layers: 1 </li>\n",
    "    <li> Hidden layer: 3, 100 neurons </li>\n",
    "    <li> Activation function in the hidden layer: \"relu\" </li>\n",
    "    <li> output activation function: \"sigmoid\" </li>\n",
    "    <li> opitimizer: \"Adam\" </li>\n",
    "    <li>batch size= 32</li>\n",
    "    <li>epochs= 100 </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP2 = tf.keras.models.Sequential(layers = None, name= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP2.add(tf.keras.layers.Dense(units= 100, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP2.add(tf.keras.layers.Dense(units= 100, activation= 'relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP2.add(tf.keras.layers.Dense(units= 100, activation= 'relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP2.add(tf.keras.layers.Dense(units= 1, activation= 'sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP2.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 6) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34892/1239436636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMLP2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\hanin\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 6) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "MLP2.fit(x_train, y_train, batch_size= 32, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2= MLP2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy against epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = MLP2.fit(x_train, y_train,validation_split = 0.1, epochs=100, batch_size=4)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Second MLP accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss against epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Second MLP loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll using the \"momentum\" optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters:\n",
    "<ul>\n",
    "    <li> Input layers: 1 </li>\n",
    "    <li> Hidden layer: 3, 150 neurons each </li>\n",
    "    <li> Activation function in the hidden layer: \"relu\" </li>\n",
    "    <li> output activation function: \"sigmoid\" </li>\n",
    "    <li> opitimizer: \"Momentum\" </li>\n",
    "    <li>batch size= 32</li>\n",
    "    <li>epochs= 100 </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3 = tf.keras.models.Sequential(layers = None, name= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3.add(tf.keras.layers.Dense(units= 150, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3.add(tf.keras.layers.Dense(units= 150, activation= 'relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3.add(tf.keras.layers.Dense(units= 150, activation= 'relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3.add(tf.keras.layers.Dense(units= 1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3.compile(optimizer= 'momentum', loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP3.fit(x_train, y_train, batch_size= 32, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3= MLP3.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy against epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = MLP3.fit(x_train, y_train,validation_split = 0.1, epochs=100, batch_size=4)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Third MLP accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss against epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Third MLP loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model on the images of size 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pklLoad('../x64.pkl', convertToNumpyArray=True)\n",
    "y = pklLoad('../y.pkl', convertToNumpyArray=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters:\n",
    "<ul>\n",
    "    <li> Input layers: 1 </li>\n",
    "    <li> Hidden layer: 2, 50 layers each </li>\n",
    "    <li> Activation function in the hidden layer: \"relu\" </li>\n",
    "    <li> output activation function: \"sigmoid\" </li>\n",
    "    <li> opitimizer: \"Adam\" </li>\n",
    "    <li>batch size= 32</li>\n",
    "    <li>epochs= 100 </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1_2 = tf.keras.models.Sequential(layers = None, name= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1_2.add(tf.keras.layers.Dense(units= 50, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1_2.add(tf.keras.layers.Dense(units= 50, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1_2.add(tf.keras.layers.Dense(units= 1, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1_2.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1_2.fit(x_train, y_train, batch_size= 32, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1_2= MLP1_2.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a820c38c0c6998d5531b30a72abed1c849220b8ccc9e18c2545958238bc5c1c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
